{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3qjiaT3God2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
        "\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from matplotlib.lines import Line2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t9Oj2kZE6C1"
      },
      "outputs": [],
      "source": [
        "# Load Dataset \n",
        "df = pd.read_csv(\"wgm.csv\")\n",
        "df = df.loc[:, ['Age', 'age_var2',  'age_var3', 'Gender', 'Education', 'EMP_2010', 'Household_Income', 'wbi', 'MH1', 'MH6', 'Subjective_Income', 'MH7A']]\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "n0t8fZp6GmKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[:, ['Age', 'age_var2',  'age_var3', 'Gender', 'Education', 'EMP_2010', 'Household_Income', 'wbi', 'MH1', 'MH6', 'Subjective_Income', 'MH7A']]\n",
        "\n",
        "print(df)\n",
        "\n",
        "# remove empty entries\n",
        "df.drop(df.index[df['Household_Income'] == ' '], inplace = True)\n",
        "df.drop(df.index[df['EMP_2010'] == ' '], inplace = True)\n",
        "df.drop(df.index[df['MH7A'] == ' '], inplace = True)\n",
        "\n",
        "# Transform categorical data ordinary data by mapping the values to integers\n",
        "df_new = pd.DataFrame() # define a new data frame and populate it with features in integer format\n",
        "\n",
        "# Age\n",
        "df_new['Age'] = df['Age']\n",
        "\n",
        "# Age Cohort\n",
        "conditions = [df['age_var3'] == '15-24', df['age_var3']== '25-34', df['age_var3']== '35-49', df['age_var2']== '50-64', df['age_var2']== '65+', df['age_var2']== 'DK/Refused']\n",
        "values = [1, 2, 3, 4, 5, 99]\n",
        "age_cohort = np.select(conditions, values, 'New')\n",
        "pd.Series(age_cohort)\n",
        "df_new['Age_Cohort'] = age_cohort\n",
        "\n",
        "# Gender\n",
        "conditions = [df['Gender'] == 'Male', df['Gender']== 'Female']\n",
        "values = [0, 1]\n",
        "gender = np.select(conditions, values, 'New')\n",
        "pd.Series(gender)\n",
        "df_new['Gender'] = gender\n",
        "\n",
        "# Education\n",
        "conditions = [df['Education'] == 'Elementary or less', df['Education']== 'Secondary', df['Education']== 'Tertiary',df['Education']== 'DK/Refused']\n",
        "values = [1, 2, 3, 99]\n",
        "education = np.select(conditions, values, 'New')\n",
        "pd.Series(education)\n",
        "df_new['Education'] = education\n",
        "\n",
        "# EMP_2010\n",
        "conditions = [df['EMP_2010'] == 'Employed full time for an employer', df['EMP_2010']== 'Employed full time for self', df['EMP_2010']== 'Employed part time do not want full time',\n",
        "df['EMP_2010']== 'Unemployed', df['EMP_2010']== 'Employed part time want full time', df['EMP_2010']== 'Out of workforce']\n",
        "values = [1,2,3,4,5,6]\n",
        "emp = np.select(conditions, values, 'New')\n",
        "pd.Series(emp)\n",
        "df_new['Employment_Status'] = emp\n",
        "\n",
        "# Household income\n",
        "conditions = [df['Household_Income'] == 'Poorest 20%', df['Household_Income']== 'Second 20%', df['Household_Income']== 'Middle 20%', df['Household_Income']== 'Fourth 20%', df['Household_Income']== 'Richest 20%']\n",
        "values = [5, 4, 3, 2, 1]\n",
        "h_income = np.select(conditions, values, 'New')\n",
        "pd.Series(h_income)\n",
        "df_new['Household_Income'] = h_income\n",
        "\n",
        "# wbi\n",
        "conditions = [df['wbi'] == 'Low income', df['wbi']== 'Lower-middle income', df['wbi']== 'Upper-middle income', df['wbi']== 'High income']\n",
        "values = [4, 3, 2, 1]\n",
        "wbi = np.select(conditions, values, 'New')\n",
        "pd.Series(wbi)\n",
        "df_new['Country_Income_Level'] = wbi\n",
        "\n",
        "# MH1\n",
        "conditions = [df['MH1'] == 'More important', df['MH1']== 'As important', df['MH1']== 'Less important', df['MH1']== 'DK/Refused']\n",
        "values = [0, 0, 1, 99]\n",
        "mh1 = np.select(conditions, values, 'New')\n",
        "pd.Series(mh1)\n",
        "df_new['Mental_Health_Importance'] = mh1\n",
        "\n",
        "# MH6\n",
        "conditions = [df['MH6'] == 'Yes', df['MH6']== 'No', df['MH6']== 'DK/Refused']\n",
        "values = [1, 0, 99]\n",
        "mh6 = np.select(conditions, values, 'New')\n",
        "pd.Series(mh6)\n",
        "df_new['MH6'] = mh6\n",
        "\n",
        "# Subjective Income\n",
        "conditions = [df['Subjective_Income'] == 'Living comfortably on present income', df['Subjective_Income']== 'Getting by on present income', df['Subjective_Income']== 'Finding it difficult on present income', \n",
        "df['Subjective_Income']== 'Finding it very difficult on present income', df['Subjective_Income']== 'DK', df['Subjective_Income']== 'Refused']\n",
        "values = [1, 2, 3, 4, 99, 99]\n",
        "subjective_income = np.select(conditions, values, 'New')\n",
        "pd.Series(subjective_income)\n",
        "df_new['Subjective_Income'] = subjective_income\n",
        "\n",
        "# MH7A\n",
        "conditions = [df['MH7A'] == 'Yes', df['MH7A']== 'No', df['MH7A']== 'DK/Refused']\n",
        "values = [1, 0, 99]\n",
        "mh7a = np.select(conditions, values, 'New')\n",
        "pd.Series(mh7a)\n",
        "df_new['Anxious_Or_Depressed'] = mh7a\n",
        "\n",
        "df_new = df_new[[ 'Age', 'Age_Cohort', 'Gender', 'Education',  'EMP_2010', 'Household_Income', 'wbi', 'MH1', 'MH6', 'Subjective_Income',  'MH7A']]\n",
        "print(df_new.head())\n",
        "df_new.dtypes\n",
        "df_new['Subjective_Income'] = pd.to_numeric(df_new['Subjective_Income'])\n",
        "\n",
        "df_new['Education'] = pd.to_numeric(df_new['Education'])\n",
        "\n",
        "# Feature Engineering-------------------------------\n",
        "\n",
        "# convert to numeric\n",
        "df_new['Age'] = pd.to_numeric(df_new['Age'])\n",
        "df_new['Age_Cohort'] = pd.to_numeric(df_new['Age_Cohort'])\n",
        "df_new['Gender'] = pd.to_numeric(df_new['Gender'])\n",
        "df_new['Household_Income'] = pd.to_numeric(df_new['Household_Income'])\n",
        "df_new['wbi'] = pd.to_numeric(df_new['wbi'])\n",
        "df_new['EMP_2010'] = pd.to_numeric(df_new['EMP_2010'])\n",
        "df_new['MH1'] = pd.to_numeric(df_new['MH1'])\n",
        "df_new['MH6'] = pd.to_numeric(df_new['MH6'])\n",
        "df_new['MH7A'] = pd.to_numeric(df_new['MH7A'])\n",
        "\n",
        "\n",
        "# clear redundant data\n",
        "df_new.drop(df_new.index[df_new['Age'] == 100], inplace = True)\n",
        "df_new.drop(df_new.index[df_new['Age_Cohort'] == 99], inplace = True)\n",
        "df_new.drop(df_new.index[df_new['Education'] == 99], inplace = True)\n",
        "df_new.drop(df_new.index[df_new['MH1'] == 99], inplace = True)\n",
        "df_new.drop(df_new.index[df_new['MH6'] == 99], inplace = True)\n",
        "df_new.drop(df_new.index[df_new['Subjective_Income'] == 99], inplace = True)\n",
        "\n",
        "\n",
        "df_new.drop(df_new.index[df_new['MH7A'] == 99], inplace = True)\n",
        "\n",
        "# delete null entries\n",
        "df_new = df_new.dropna()\n",
        "\n",
        "df_new.dtypes\n",
        "\n",
        "#df.columns[df.isin([25]).any()]\n",
        "df_y = df_new['MH7A']\n",
        "df_x = df_new.drop(columns=['MH7A'])\n",
        "df_new = pd.concat([df_x, df_y], axis=1)\n",
        "print(df_new)"
      ],
      "metadata": {
        "id": "idhjmQl_H9o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_new.columns[df_new.isin([99]).any()]"
      ],
      "metadata": {
        "id": "hrWnR6jdK-kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y = df_new['MH7A']\n",
        "df_X = df_new.drop(columns=['MH7A'])\n",
        "df_new = pd.concat([df_X, df_y], axis=1)\n",
        "df = df_new\n",
        "print(df)"
      ],
      "metadata": {
        "id": "JXF30u7_Mq45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "X = df_X.to_numpy() \n",
        "y = df_y.to_numpy()\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "bul1YMp-Rv9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Coefficients \n",
        "def plot_coeff(model):\n",
        "    data = model.coef_[0]\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    ax = plt.subplot()\n",
        "    plt.barh(np.arange(data.size),data)\n",
        "    ax.set_yticks(np.arange(data.size))\n",
        "    ax.set_yticklabels(labels)\n",
        "    plt.show()\n",
        "\n",
        "# Accuracy Score\n",
        "def get_accuracy_score(model,  ypred_train, ypred_test):\n",
        "    print(\"Training Accuracy: \" , accuracy_score(ytrain, ypred_train))\n",
        "    print(\"Test Accuracy: \" , accuracy_score(ytest, ypred_test))\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "def plot_confusion_matrix(model, ytest, ypred):\n",
        "    cm = confusion_matrix(ytest,ypred) #y = ytest\n",
        "    color = 'white'\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "    disp.plot()\n",
        "    plt.show()\n",
        "\n",
        "# Plot ROC Curve\n",
        "def plot_roc_curve(model, model_type, Xtest, ytest):\n",
        "    plt.rc('font', size=18); plt.rcParams['figure.constrained_layout.use'] = True\n",
        "\n",
        "    if model_type == \"ridge\":\n",
        "        y_scores = model._predict_proba_lr(Xtest) \n",
        "    else:\n",
        "        y_scores = model.predict_proba(Xtest)\n",
        "   \n",
        "    fpr, tpr, threshold = roc_curve(ytest, y_scores[:, 1])\n",
        "\n",
        "    plt.plot(fpr,tpr)\n",
        "    plt.xlabel('False positive rate')\n",
        "    plt.ylabel('True positive rate')\n",
        "    plt.plot([0, 1], [0, 1], color='green',linestyle='--')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "OwLC0pZKMwkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use optimal polynomial degree observed from Cross Validation\n",
        "def find_penalty(data, classifier, range):\n",
        "    X = data\n",
        "    # Error bar for C values\n",
        "    mean_error_train=[]\n",
        "    std_error_train=[]\n",
        "    mean_error=[]\n",
        "    std_error=[]\n",
        "\n",
        "    for c in range:\n",
        "        if classifier == \"logistic\":\n",
        "            model = LogisticRegression(penalty='l2', max_iter = 1000, C=c)\n",
        "        else:\n",
        "            model = RidgeClassifier(alpha=1/(2*c))\n",
        "        temp_train = []\n",
        "        temp=[]\n",
        "\n",
        "        kf = KFold(n_splits=5)\n",
        "        for train, test in kf.split(X):\n",
        "            model.fit(X[train], y[train])\n",
        "            ypred_train = model.predict(X[train])\n",
        "            ypred = model.predict(X[test])\n",
        "\n",
        "            temp_train.append(accuracy_score(y[train],ypred_train))\n",
        "            temp.append(accuracy_score(y[test],ypred))\n",
        "\n",
        "        # print(model.intercept_, model.coef_)\n",
        "        mean_error_train.append(np.array(temp_train).mean())\n",
        "        std_error_train.append(np.array(temp_train).std())\n",
        "        mean_error.append(np.array(temp).mean())\n",
        "        std_error.append(np.array(temp).std())\n",
        "\n",
        "    label_size = 20\n",
        "    plt.figure(figsize=(30,10))\n",
        "    plt.rc('axes', labelsize=label_size) \n",
        "    plt.errorbar(range, mean_error, yerr=std_error)\n",
        "    plt.errorbar(range, mean_error_train, yerr=std_error_train)\n",
        "    plt.xlabel('Penalty (C)')\n",
        "    plt.ylabel('Accuracy Score')\n",
        "    plt.xlim((-0.5,2))\n",
        "    plt.legend(handles=[Line2D([], [], c=\"orange\", label=\"Train\"),Line2D([], [], c=\"blue\", label=\"Test\"),])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "moDeb6wBS7eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Classifier\n",
        "model_logistic = LogisticRegression(penalty='l2', max_iter=1000, C = 100).fit(Xtrain, ytrain)\n",
        "print(model_logistic.intercept_, model_logistic.coef_)"
      ],
      "metadata": {
        "id": "4tZYbr_iVZIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold Cross Validation for range of C values\n",
        "find_penalty(X, classifier = \"logistic\", range = [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 50, 75, 100])"
      ],
      "metadata": {
        "id": "esigdDxAUDAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_logistic_optimal = LogisticRegression(penalty='l2',max_iter=1000, C=0.01).fit(Xtrain, ytrain)"
      ],
      "metadata": {
        "id": "Y1JemnNpbRPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(df_X.columns.values)"
      ],
      "metadata": {
        "id": "76nt6XCrgokP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Coefficients \n",
        "plot_coeff(model_logistic_optimal)\n",
        "\n",
        "# Accuracy Score for Logistic Regression\n",
        "model = model_logistic_optimal\n",
        "ypred_train = model.predict(Xtrain)\n",
        "ypred_test = model.predict(Xtest)\n",
        "get_accuracy_score(model,  ypred_train, ypred_test)\n",
        "\n",
        "# Confusion Matrix for Logistic Regression\n",
        "plot_confusion_matrix(model, ytest, ypred_test)\n",
        "\n",
        "# ROC Curve for Logistic Regression\n",
        "plot_roc_curve(model, \"logistic\", Xtest, ytest)\n",
        "\n",
        "# Performance Metrics for Logistic Regression model\n",
        "print(\"Training Data\")\n",
        "print(classification_report(ytrain, ypred_train))\n",
        "print(\"Test Data\")\n",
        "print(classification_report(ytest, ypred_test))"
      ],
      "metadata": {
        "id": "7oSn6PUMwsm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridge Classifier\n",
        "C = 0.1\n",
        "model_ridge = RidgeClassifier(alpha=1/(2*C)).fit(Xtrain, ytrain)\n",
        "print(model_ridge.intercept_, model_ridge.coef_)"
      ],
      "metadata": {
        "id": "E-dsuE-Eli-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold Cross Validation for range of C values\n",
        "find_penalty(X, classifier = \"ridge\", range = [0.001, 0.005, 0.01, 0.1, 0.5, 1, 5, 10, 50])"
      ],
      "metadata": {
        "id": "RfhOEgHV8Nan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C = 0.05\n",
        "model_ridge_optimal = RidgeClassifier(alpha=1/(2*C)).fit(Xtrain, ytrain)"
      ],
      "metadata": {
        "id": "Dd-vbqnFN65R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Coefficients \n",
        "plot_coeff(model_ridge_optimal)\n",
        "\n",
        "# Accuracy Score for Ridge Regression\n",
        "model = model_ridge_optimal\n",
        "ypred_train = model.predict(Xtrain)\n",
        "ypred_test = model.predict(Xtest)\n",
        "get_accuracy_score(model,  ypred_train, ypred_test)\n",
        "\n",
        "# Confusion Matrix for Ridge Regression\n",
        "plot_confusion_matrix(model, ytest, ypred_test)\n",
        "\n",
        "# ROC Curve for Ridge Regression\n",
        "plot_roc_curve(model, \"ridge\", Xtest, ytest)\n",
        "\n",
        "# Performance Metrics for Ridge Regression model\n",
        "print(\"Training Data\")\n",
        "print(classification_report(ytrain, ypred_train))\n",
        "print(\"Test Data\")\n",
        "print(classification_report(ytest, ypred_test))"
      ],
      "metadata": {
        "id": "T84kWdTs0aVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kernelized-SVM \n",
        "model_svc_sig = SVC(C = 0.1, kernel='sigmoid', degree=3, probability=True).fit(Xtrain, ytrain)"
      ],
      "metadata": {
        "id": "2eF31vEqn_5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_svc_sig.intercept_, model_svc_sig.dual_coef_)"
      ],
      "metadata": {
        "id": "wPaClWkEbYsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Score for Kernelised-SVM\n",
        "model = model_svc_sig\n",
        "ypred_train = model.predict(Xtrain)\n",
        "ypred_test = model.predict(Xtest)\n",
        "get_accuracy_score(model,  ypred_train, ypred_test)\n",
        "\n",
        "# Confusion Matrix for Kernelised-SVM\n",
        "plot_confusion_matrix(model, ytest, ypred_test)\n",
        "\n",
        "# ROC Curve for Kernelised-SVM\n",
        "plot_roc_curve(model, \"svm\", Xtest, ytest)\n",
        "\n",
        "# Performance Metrics for Kernelised-SVM\n",
        "print(\"Training Data\")\n",
        "print(classification_report(ytrain, ypred_train))\n",
        "print(\"Test Data\")\n",
        "print(classification_report(ytest, ypred_test))"
      ],
      "metadata": {
        "id": "EaFzaKfgiUoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline Classifier - Random\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "model_baseline_rand = DummyClassifier(strategy='uniform')\n",
        "model_baseline_rand.fit(Xtrain, ytrain)\n",
        "\n",
        "ypred_test = model_baseline_rand.predict(Xtest)\n",
        "\n",
        "# Accuracy for Baseline model \n",
        "print(accuracy_score(ytest, ypred_test))"
      ],
      "metadata": {
        "id": "l8sCkIPcUTtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_baseline_rand\n",
        "# Confusion Matrix for Baseline\n",
        "plot_confusion_matrix(model, ytest, ypred_test)\n",
        "\n",
        "# ROC Curve for Baseline\n",
        "plot_roc_curve(model, \"baseline\", Xtest, ytest)\n",
        "\n",
        "# Performance Metrics for Baseline\n",
        "print(\"Training Data\")\n",
        "print(classification_report(ytrain, ypred_train))\n",
        "print(\"Test Data\")\n",
        "print(classification_report(ytest, ypred_test))"
      ],
      "metadata": {
        "id": "FaPqcG88BCo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline Classifier - Most Frequent\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "model_baseline_freq = DummyClassifier(strategy='most_frequent')\n",
        "model_baseline_freq.fit(Xtrain, ytrain)\n",
        "ypred_test = model_baseline_freq.predict(Xtest)\n",
        "\n",
        "# Accuracy for Baseline model \n",
        "print(accuracy_score(ytest, ypred_test))"
      ],
      "metadata": {
        "id": "CBILOPhvSlJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_baseline_freq\n",
        "# Confusion Matrix for Baseline\n",
        "plot_confusion_matrix(model, ytest, ypred_test)\n",
        "\n",
        "# ROC Curve for Baseline\n",
        "plot_roc_curve(model, \"baseline\", Xtest, ytest)\n",
        "\n",
        "# Performance Metrics for Baseline\n",
        "print(\"Training Data\")\n",
        "print(classification_report(ytrain, ypred_train))\n",
        "print(\"Test Data\")\n",
        "print(classification_report(ytest, ypred_test))"
      ],
      "metadata": {
        "id": "R8aqce9LBhzE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
